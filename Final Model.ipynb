{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "\n",
    "'''Features'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.stats import norm, multinomial\n",
    "\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import cycle\n",
    "from scipy import interp\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "'''Display'''\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('fruit_data_with_colors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'apple', 2: 'mandarin', 3: 'orange', 4: 'lemon'}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping fruit label value to fruit name to make results easier to interpret\n",
    "look_up_fruit_name = dict(zip(df.fruit_label.unique(), df.fruit_name.unique()))\n",
    "look_up_fruit_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Training and Test Sets and Apply Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (44, 3)\n",
      "Training Labels Shape: (44,)\n",
      "Testing Features Shape: (15, 3)\n",
      "Testing Labels Shape: (15,)\n"
     ]
    }
   ],
   "source": [
    "X = df[['mass', 'width', 'height']] #Based on the result of correlation matrix\n",
    "y = df['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34299972 0.32775265 0.32924762]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importance = pd.Series(model.feature_importances_, index = X.columns)\n",
    "feat_importance.nlargest(10).plot(kind = 'barh')\n",
    "plt.savefig('fruits_featureI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier using the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the accuracy of the classifier on future data, using the test data\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scalling & feature selection the accuracy went up. Which proves the model can be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orange'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the trained k-NN classifier model to classify new, previously unseen objects\n",
    "# first example: a small fruit with mass 20g, width 4.3 cm, height 5.5 cm\n",
    "fruit_prediction = knn.predict([[20, 4.3, 5.5]])\n",
    "look_up_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orange'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruit_prediction = knn.predict([[100, 6.3, 8.5]])\n",
    "look_up_fruit_name[fruit_prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 2 0]\n",
      " [0 2 0 0]\n",
      " [1 0 3 0]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57         4\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.60      0.75      0.67         4\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.82      0.81      0.81        15\n",
      "weighted avg       0.80      0.80      0.80        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decsision Tree</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model_name accuracy_score precision_score recall_score  \\\n",
       "6                  XGBClassifier           0.80            0.84         0.82   \n",
       "10          ExtraTreesClassifier           0.80            0.84         0.82   \n",
       "1    Stochastic Gradient Descent           0.80            0.82         0.81   \n",
       "5           Gaussian Naive Bayes           0.80            0.82         0.81   \n",
       "2                  Random Forest           0.73            0.81         0.78   \n",
       "8   Linear Discriminant Analysis           0.73            0.75         0.75   \n",
       "3                 Decsision Tree           0.60            0.70         0.65   \n",
       "7   Gradient Boosting Classifier           0.53            0.70         0.60   \n",
       "4                       AdaBoost           0.53            0.59         0.60   \n",
       "9             LogisticRegression           0.53            0.46         0.46   \n",
       "0                          Dummy           0.27            0.07         0.25   \n",
       "\n",
       "   f1_score  \n",
       "6      0.83  \n",
       "10     0.83  \n",
       "1      0.81  \n",
       "5      0.81  \n",
       "2      0.78  \n",
       "8      0.73  \n",
       "3      0.66  \n",
       "7      0.61  \n",
       "4      0.53  \n",
       "9      0.43  \n",
       "0      0.11  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dict of the models\n",
    "model_dict = {'Dummy' : DummyClassifier(),\n",
    "              'Stochastic Gradient Descent' : SGDClassifier(),\n",
    "              'Random Forest': RandomForestClassifier(),\n",
    "              'Decsision Tree': DecisionTreeClassifier(),\n",
    "              'AdaBoost': AdaBoostClassifier(),\n",
    "              'Gaussian Naive Bayes': GaussianNB(),\n",
    "              'XGBClassifier' : XGBClassifier(),\n",
    "              'Gradient Boosting Classifier' : GradientBoostingClassifier(),\n",
    "              'Linear Discriminant Analysis' : LinearDiscriminantAnalysis(),\n",
    "              'LogisticRegression' : LogisticRegression(),\n",
    "              'ExtraTreesClassifier' : ExtraTreesClassifier()}\n",
    "\n",
    "\n",
    "#Function to get the scores for each model \n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "model_score_df(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model based on the results above is Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n",
    "        tmin, tsec = divmod(temp_sec, 60)\n",
    "        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators Number of trees in random forest\n",
    "# max_features Number of features to consider at every split\n",
    "# max_depth Maximum number of levels in tree\n",
    "# Minimum number of samples required to split a node\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']}\n",
    "\n",
    "gridsearch = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 3 minutes and 41.86 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = timer(None) # timing starts from this point for \"start_time\" variable\n",
    "model = gridsearch.fit(X_train, y_train)\n",
    "timer(start_time) # timing ends here for \"start_time\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 4,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_model = RandomForestClassifier(criterion = 'gini',\n",
    " max_depth = 4, max_features = 'auto', n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing classification report\n",
      "Random Forest Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57         4\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.60      0.75      0.67         4\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.82      0.81      0.81        15\n",
      "weighted avg       0.80      0.80      0.80        15\n",
      "\n",
      "Accuracy is 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Best performing classification report\")\n",
    "print(\"Random Forest Classifier\")\n",
    "rf_best_model.fit(X_train, y_train)\n",
    "pred = rf_best_model.predict(X_test)\n",
    "#print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))\n",
    "print('Accuracy is %s' % accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
